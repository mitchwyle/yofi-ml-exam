# -*- coding: utf-8 -*-
"""Yofi's Assignment 1 Notebook

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AAYQAAMKzFrBAJ-LQFSVrrf99A4PyCjo

# **Assignment 1: Cell Segmentation with a U-Net**

# **Question 1**: How would a cell segmentation program help you with your current rotation project? (5 pts)

**Ans:** In my current rotation project, I need to measure the circularity of cells to investigate how stiffness effects tumorgenesis. Healthy, wildtype cells are more round compared to the cancerous, invasive cells. Currently, I use imageJ processing to create an outline of each cell and run a java script to quantify the circularity. If the cell segmentation program could make a clear outline from a BF image it would save me a lot of time instead of trying to outline each cell by hand. Using computational and machine learning approaches for simple quantification like my rotation project image analysis increases the accuracy, reproducibility, and robustness of most any data set.

# Download cell images

Just run this section.
"""

# Install the program gdown using the python pip command
!pip install gdown

# Fluo-N2DL-HeLa.zip
!gdown https://drive.google.com/uc?id=1dfPWLUFCajb8igZlO9HiKi8j-uAzV1M8

# List the current directory (see files have been downloaded)
!ls

# Unzip the directory
!unzip Fluo-N2DL-HeLa.zip
!ls

!ls Fluo-N2DL-HeLa

!ls Fluo-N2DL-HeLa/01

!ls Fluo-N2DL-HeLa/01_ST

!ls Fluo-N2DL-HeLa/01_ST/SEG

from skimage.io import imread, imshow

img = imread('Fluo-N2DL-HeLa/01/t000.tif')
imshow(img)

img = imread('Fluo-N2DL-HeLa/01_ST/SEG/man_seg000.tif')
imshow(img)

"""# **Question 2**: Four questions about images (5 pts total)"""

from skimage.io import imread, imshow

# Let's load an image into the img variable
img = imread('Fluo-N2DL-HeLa/01/t000.tif')

"""## **Question 2A**: What is the data type of the img variable? Write a line of code that shows the data type of img (1 pt)."""

# Ans 2A
type(img)

"""## **Question 2B**: What is the size of the image (dimensions = height x width)? Write a line of code that tells you the image size (1 pt)."""

# Ans 2B:
print(img.shape)

"""## **Question 2C**: Is the image RGB or grayscale? How do you know without looking at it? (1 pt)

**Ans 2C:** There is no RGC channel (3) under the information presented in img.shape, which would suggest that this is a **grayscale**,

## **Question 2D**: In the cell below, resize the image so that it is twice its original size. Show the original image and the new image (2 pts).
"""

#@title Default title text
# Ans 2D:
from skimage.transform import resize
imshow(img)

from skimage.transform import resize 
from skimage import data

import numpy as np

img_big = np.resize(img,(1400,2200))
imshow(img_big)

"""# Dataset Processing and **Question 3** (5 pts total)"""

import random
import warnings

import numpy as np

import matplotlib.pyplot as plt

from tqdm import tqdm
#from itertools import chain
from skimage.io import imread, imshow
from skimage.transform import resize
from skimage.morphology import label

# All images will be resized to 512 x 512
# UNets work best when image size is square and a power of 2
IMG_WIDTH = 512
IMG_HEIGHT = 512
IMG_CHANNELS = 1

"""## Make training set image tensor"""

import glob
# Use the glob program to read in the names of files in specified directory
image_ids = sorted(glob.glob('Fluo-N2DL-HeLa/01/*.tif'))

print(image_ids)

mask_ids = sorted(glob.glob('Fluo-N2DL-HeLa/01_ST/SEG/*.tif'))

"""## **Question 3A**: Write a function that will normalize the pixel values of an image to between 0 and 1 and then return that normalized image. In the Lecture 3 Notebook, we accomplished this task on the whole tensor of images all at once. Here, we will do it image by image. (3 pts)"""

# Ans 3A:

def normalize_img(img):
    # Input is an image
    # (1) calculate maximum pixel in image
    tMax = np.amax(img)
    # (2) calculate the minimum pixel in image
    tMin = np.amin(img)
    # (3) We want the minimum pixel in image to have value 0, and maximum pixel to have value 1.
    # Look what we did in the Lecture 3 notebook to normalize the image, but remember the minimum 
    # pixel value was 0 which it is not now.
    norm_img = (img-tMin)/(tMax - tMin)

    return norm_img

# This function makes the image data tensor from the image file ids. It also normalizes and resizes the images. Finally the new image list
# is converted into a numpy array (tensor).
def makeImageDataTensor(img_ids):
    img_list = []

    for i_id in tqdm(img_ids, total=len(img_ids)):

        img = imread(i_id)

        norm_img = normalize_img(img)
        #resize
        resize_norm_img = resize(norm_img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
  
        img_list.append(resize_norm_img)

    img_array = np.array(img_list)

    return img_array

# Create image data tensor. Below it will be expanded by one dimension before being fed into U-Net
X_train_ = makeImageDataTensor(image_ids)

# This function makes the mask data tensor from the mask file ids.
def makeMaskDataTensor(mask_ids):

    mask_list = []
    for m_id in tqdm(mask_ids, total=len(mask_ids)):
        img = imread(m_id)

        binary_img = (img > 0.0)

        resize_binary_img = resize(binary_img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)

        mask_list.append(resize_binary_img)


    mask_array = np.array(mask_list,dtype=np.bool)

    return mask_array

# Create mask data tensor.
Y_train_ = makeMaskDataTensor(mask_ids)

# Remember all CNNs including U-Nets require that the image have 3 dimensions: height, width, and channel
# For grayscale images, we need to add an extra (dummy) channel dimension.
X_train = np.expand_dims(X_train_, axis=-1)
Y_train = np.expand_dims(Y_train_, axis=-1)

print(X_train_.shape,Y_train_.shape)
print(X_train.shape,Y_train.shape)

# Let's look at a sample image
imshow(X_train_[0])

# Let's look at the correponding mask
imshow(Y_train_[0])

"""## **Question 3B**: How many training images are there? (1 pt)"""

# Ans 3B: Write a line of code that shows how many training images there are, and then fill in the answer in the comment line.
!ls
!pwd
print(X_train_.shape,Y_train_.shape)

# Number of training images = 92

"""## Load test data"""

import glob
# Use the glob program to read in the names of files in specified directory
test_image_ids = sorted(glob.glob('Fluo-N2DL-HeLa/02/*.tif'))

test_mask_ids = sorted(glob.glob('Fluo-N2DL-HeLa/02_ST/SEG/*.tif'))

X_test_ = makeImageDataTensor(test_image_ids)

Y_test_ = makeMaskDataTensor(test_mask_ids)

X_test = np.expand_dims(X_test_, axis=-1)
Y_test = np.expand_dims(Y_test_, axis=-1)

"""## **Question 3C**: How many test images are there? (1 pt)"""

# Ans 3C: Write a line of code that shows how many test images there are, and then fill in the answer in the comment line.

print(X_test_.shape,Y_test_.shape)
# Number of test images = 92

"""# **Question 4**: Make the following changes to the U-Net training process (5 pts total)

**4A)** Increase the validation set from 10% to 15% of the training set (1.5 pts).

**4B)** Increase the number of epochs to 120 (1.5 pts).

**4C)** Change the performance metric from the mean_iou function to the iou function (2 pts).

# Construct U-Net

Because it is a special architecture, it has more layers and extra connections (cross) compared to CNN used on MNIST. We won't take advantage of the sequential model structure in Keras but will link together the layers in our own code. We will still take advantage of the pre-defined Keras layers such as Conv2D.
"""

import numpy as np

from keras.models import Model, load_model
from keras.layers import BatchNormalization, UpSampling2D 
from keras.layers import Input
from keras.layers.core import Dropout, Lambda
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D
from keras.layers.merge import concatenate
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import backend as K
from keras import optimizers

import tensorflow as tf

# Define IoU metric. 
# We will use IoU instead of standard accuracy metrics (%correct, F1, etc.)
# There are different versions of IoU, and we will use the simplest definition (iou)

def iou(y_true, y_pred, smooth=1.):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)

def iou_thresholded(y_true, y_pred, threshold=0.5, smooth=1.):
    y_pred = threshold_binarize(y_pred, threshold)
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)

def mean_iou(y_true, y_pred):
    prec = []
    for t in np.arange(0.5, 1.0, 0.05):
        y_pred_ = tf.to_int32(y_pred > t)
        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)
        K.get_session().run(tf.local_variables_initializer())
        with tf.control_dependencies([up_opt]):
            score = tf.identity(score)
        prec.append(score)
    return K.mean(K.stack(prec), axis=0)

# Define a convolution block consisting of two convolution layers
def conv2d_block(
    inputs, 
    use_batch_norm=True, 
    dropout=0.3, 
    filters=16, 
    kernel_size=(3,3), 
    activation='elu', 
    kernel_initializer='he_normal', 
    padding='same'):
    
    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (inputs)
    if use_batch_norm:
        c = BatchNormalization()(c)
    if dropout > 0.0:
        c = Dropout(dropout)(c)
    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (c)
    if use_batch_norm:
        c = BatchNormalization()(c)
    return c

# Build U-Net model layer-by-layer with buildUNet() function

# The input size will be the size of the resized images specified above
# These dimensions have been set above
# IMG_WIDTH = 512
# IMG_HEIGHT = 512
# IMG_CHANNELS = 1

def buildUNet():

    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    s = inputs

    # Each block corresponds to unit in U-Net schematic slide
    # Input
    c1 = conv2d_block(inputs=s, filters=16, use_batch_norm=False, dropout=0.1)
    p1 = MaxPooling2D((2, 2)) (c1)

    # Down-1
    c2 = conv2d_block(inputs=p1, filters=32, use_batch_norm=False, dropout=0.1)
    p2 = MaxPooling2D((2, 2)) (c2)

    # Down-2
    c3 = conv2d_block(inputs=p2, filters=64, use_batch_norm=False, dropout=0.2)
    p3 = MaxPooling2D((2, 2)) (c3)

    # Down-3
    c4 = conv2d_block(inputs=p3, filters=128, use_batch_norm=False, dropout=0.2)
    p4 = MaxPooling2D((2, 2)) (c4)

    # Bottom
    c5 = conv2d_block(inputs=p4, filters=256, use_batch_norm=False, dropout=0.3)

    # Up-3
    # Conv2DTranspose is a convolution that upsamples (increases image/map size) by adding padding to its input
    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    c6 = conv2d_block(inputs=u6, filters=128, use_batch_norm=False, dropout=0.2)

    # Up-2
    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    c7 = conv2d_block(inputs=u7, filters=64, use_batch_norm=False, dropout=0.2)

    # Up-1
    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    c8 = conv2d_block(inputs=u8, filters=32, use_batch_norm=False, dropout=0.1)

    # Output
    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = conv2d_block(inputs=u9, filters=16, use_batch_norm=False, dropout=0.1)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    return inputs, outputs

inputs, outputs = buildUNet()

# Create model by specifying input and ouptput tensor shapes
# Corresponds to model = models.Sequential() from MNIST CNN example
model = Model(inputs=[inputs], outputs=[outputs])
# Specify learning rate parameters for optimizer called Adam; we are only concerned with base learning rate.
adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)
# Compile model with optimizer, loss-function, and the metric which is our iou function
model.compile(optimizer=adam, loss='binary_crossentropy', metrics=[iou])
model.summary()

"""# Train U-Net model"""

# Stop early if no improvement in training (on validation performance)
earlystopper = EarlyStopping(patience=20, verbose=1)
# Save best model on validation set
checkpointer = ModelCheckpoint('model-cell-1.h5', verbose=1, save_best_only=True)
# Fit model on training data for number of stated epochs; 0.1 of training data will be validation set
results = model.fit(X_train, Y_train, validation_split=0.15, batch_size=8, epochs=120, 
                    callbacks=[earlystopper, checkpointer])

# Plot the loss and IoU on training and validation datasets as a function of epochs to show the learning process
import matplotlib.pyplot as plt

history = results
print(history.history.keys())

# This function takes as input the results (history) from model.fit() and plots loss and IoU accuracy as function of epochs
def makeTrainingPlots(history):

    # change back to iou
    acc = history.history['iou']
    val_acc = history.history['val_iou']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs = range(len(acc))

    fig, axes = plt.subplots(1,2, figsize=(15,5))     
    axes[0].set_title('Training and validation loss', fontsize=15) 
    axes[0].plot(epochs, loss, 'bo', label='Training loss')
    axes[0].plot(epochs, val_loss, 'b', label='Validation loss')
    axes[0].legend()

    axes[1].set_title('Training and validation accuracy', fontsize=15) 
    axes[1].plot(epochs, acc, 'bo', label='Training acc')
    axes[1].plot(epochs, val_acc, 'b', label='Validation acc')
    axes[1].legend()

    plt.show()

# Call plotting function
makeTrainingPlots(history)

"""# **Question 5**: What is the best result you can get? (5 pts)

1) Copy the Construct U-Net and Train U-Net model sections from above to below this header cell. This is so you don't overwrite the cells above.

2) Vary the hyperparameters (i.e. learning rate, number of epochs, etc.) until you find the hyperparameters that give you the lowest validation loss (val_loss). Do the best you can. There is no right answer.

3) Use the best model (i.e. load the weights) to evaluate over the test set data.

4) Print out the test loss and test accuracy (iou)

You can keep re-running the training in the same cells (as you vary the hyperparameters) and just remember the hyperparameter values that gave you your best validation loss result. Then at the end re-run with your best hyperparameters.

This is basically what people do when performing machine learning.
"""

# Put the Construct U-Net and Train U-Net cells below:
import numpy as np

from keras.models import Model, load_model
from keras.layers import BatchNormalization, UpSampling2D 
from keras.layers import Input
from keras.layers.core import Dropout, Lambda
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D
from keras.layers.merge import concatenate
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import backend as K
from keras import optimizers

import tensorflow as tf

def iou(y_true, y_pred, smooth=1.):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)

def iou_thresholded(y_true, y_pred, threshold=0.5, smooth=1.):
    y_pred = threshold_binarize(y_pred, threshold)
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)

def mean_iou(y_true, y_pred):
    prec = []
    for t in np.arange(0.5, 1.0, 0.05):
        y_pred_ = tf.to_int32(y_pred > t)
        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)
        K.get_session().run(tf.local_variables_initializer())
        with tf.control_dependencies([up_opt]):
            score = tf.identity(score)
        prec.append(score)
    return K.mean(K.stack(prec), axis=0)

def conv2d_block(
    inputs, 
    use_batch_norm=True, 
    dropout=0.3, 
    filters=16, 
    kernel_size=(3,3), 
    activation='elu', 
    kernel_initializer='he_normal', 
    padding='same'):
    
    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (inputs)
    if use_batch_norm:
        c = BatchNormalization()(c)
    if dropout > 0.0:
        c = Dropout(dropout)(c)
    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (c)
    if use_batch_norm:
        c = BatchNormalization()(c)
    return c

def buildUNet():

    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    s = inputs

    # Each block corresponds to unit in U-Net schematic slide
    # Input
    c1 = conv2d_block(inputs=s, filters=16, use_batch_norm=False, dropout=0.1)
    p1 = MaxPooling2D((2, 2)) (c1)

    # Down-1
    c2 = conv2d_block(inputs=p1, filters=32, use_batch_norm=False, dropout=0.1)
    p2 = MaxPooling2D((2, 2)) (c2)

    # Down-2
    c3 = conv2d_block(inputs=p2, filters=64, use_batch_norm=False, dropout=0.2)
    p3 = MaxPooling2D((2, 2)) (c3)

    # Down-3
    c4 = conv2d_block(inputs=p3, filters=128, use_batch_norm=False, dropout=0.2)
    p4 = MaxPooling2D((2, 2)) (c4)

    # Bottom
    c5 = conv2d_block(inputs=p4, filters=256, use_batch_norm=False, dropout=0.3)

    # Up-3
    # Conv2DTranspose is a convolution that upsamples (increases image/map size) by adding padding to its input
    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    c6 = conv2d_block(inputs=u6, filters=128, use_batch_norm=False, dropout=0.2)

    # Up-2
    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    c7 = conv2d_block(inputs=u7, filters=64, use_batch_norm=False, dropout=0.2)

    # Up-1
    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    c8 = conv2d_block(inputs=u8, filters=32, use_batch_norm=False, dropout=0.1)

    # Output
    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = conv2d_block(inputs=u9, filters=16, use_batch_norm=False, dropout=0.1)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    return inputs, outputs

inputs, outputs = buildUNet()


model = Model(inputs=[inputs], outputs=[outputs])
# Specify learning rate parameters for optimizer called Adam; we are only concerned with base learning rate.
adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)
# Compile model with optimizer, loss-function, and the metric which is our iou function
model.compile(optimizer=adam, loss='binary_crossentropy', metrics=[iou])
# Stop early if no improvement in training (on validation performance)
earlystopper = EarlyStopping(patience=20, verbose=1)
# Save best model on validation set
checkpointer = ModelCheckpoint('model-cell-1.h5', verbose=1, save_best_only=True)
# Fit model on training data for number of stated epochs; 0.1 of training data will be validation set
results = model.fit(X_train, Y_train, validation_split=0.15, batch_size=8, epochs=120, 
                    callbacks=[earlystopper, checkpointer])
import matplotlib.pyplot as plt

history = results
print(history.history.keys())

# This function takes as input the results (history) from model.fit() and plots loss and IoU accuracy as function of epochs
def makeTrainingPlots(history):

    # change back to iou
    acc = history.history['iou']
    val_acc = history.history['val_iou']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs = range(len(acc))

    fig, axes = plt.subplots(1,2, figsize=(15,5))     
    axes[0].set_title('Training and validation loss', fontsize=15) 
    axes[0].plot(epochs, loss, 'bo', label='Training loss')
    axes[0].plot(epochs, val_loss, 'b', label='Validation loss')
    axes[0].legend()

    axes[1].set_title('Training and validation accuracy', fontsize=15) 
    axes[1].plot(epochs, acc, 'bo', label='Training acc')
    axes[1].plot(epochs, val_acc, 'b', label='Validation acc')
    axes[1].legend()

    plt.show()

# Call plotting function
makeTrainingPlots(history)

"""# **Questions 6 and 7**: Segmenting Yeast Cells (10 pts)

Prof. Yi took some of his random yeast cell images and wondered if the predictor trained on HeLa cells could also segment a different cell type.

Download two images of yeast cells: (1) Fus3_t0.tif (Fus3-GFP) and (2) Yeast_PI-1.jpg (yeast cells stained with propidium iodide)
"""

!gdown https://drive.google.com/uc?id=13ZuIZVxrX_ich2_jytTE7B08bPv_Rb1g

!gdown https://drive.google.com/uc?id=1NixjI8LzMFUdx_ohuABXYLvGCpmS51eT

!ls

img = imread('Fus3_t0.tif')
imshow(img)

"""The Fus3_t0.tif image is RGB and we need to convert to grayscale and save it. We did this before in Homework 1.

## **Question 6A**: Convert Fus3_t0 into a grayscale image and display it (1 pt)
"""

from skimage.color import rgb2gray
from skimage.io import imsave

# Ans:

gray_img = rgb2gray(img)
imshow(gray_img)

"""**Save** the grayscale image as Fus3_t0_gray.tif"""

imsave('Fus3_t0_gray.tif',gray_img)

"""## **Question 6B:** Read in and display Yeast_PI-1 (1 pt)"""

# Commented out IPython magic to ensure Python compatibility.
# Ans 6B:
# %cd content/
img1 = imread('Yeast_PI-1.jpg')
img2 = imread('Fus3_t0_gray.tif')
imshow(img1)

"""## **Question 6C**: What are the sizes (dimensions = height x width) of the two images? Write the line(s) of code that show the dimensions of the 2 images. (1 pt)"""

# Ans 6C corresponds to lecture 3 go through data set processing train_ids file names of all training images gets fed into make data tensor
#print yeastids look at IMAGE_IDS:
print(img1.shape)
print(img2.shape)

"""## **Question 6D**: Create a list called yeast_ids with the names of the yeast image files. Use the grayscale image of Fus3_t0. See image_ids or mask_ids for examples. (1 pt)"""

# Ans 6D:
yeast_ids = ['Fus3_t0_gray.tif', 'Yeast_PI-1.jpg']
!ls

"""## **Question 6E**: Use the makeImageDataTensor function to create the image tensor X_yeast_ (1 pt)"""

#Ans 6E: WE RAN RESHAPE ON LECTURE 2 notebook

X_yeast = makeImageDataTensor(yeast_ids)

"""We need to add the extra channel dimension before feeding in to neural network"""

print(X_yeast.shape)

X_yeast = np.expand_dims(X_yeast, axis=-1)
print(X_yeast.shape)

"""## **Question 7A**: Use the best model trained above in Question 5 to make the predictions (prediction mask) on the yeast images. (2.5 pts)"""

# Ans 7A:
model.load_weights('model-cell-1.h5')
Y_test_predictions = model.predict(X_yeast)

"""**Don't forget to squeeze the prediction masks** before displaying them in the next section (see Lecture 3 notebook)."""

# Squeeze prediction tensor
Y_test_sq = np.squeeze(X_yeast) #squeezes out extra dimension (1) which doesn't do anything
Y_test_predict_sq = np.squeeze(Y_test_predictions)
X_test_sq = np.squeeze(X_test) #squeezes out extra dimension (1) which doesn't do anything

print(Y_test_sq.shape, Y_test_predict_sq.shape)

"""## **Question 7B**: Display the two original yeast images along side the prediction masks (2.5 pts)"""

# Ans 7B:
# Display images/masks in two rows and two columns: First row is Fus3 image and second row is PI image.
# First column is original image, and second column is the prediction mask. There should be 4 pictures altogether.
fig, axes = plt.subplots(2,2, figsize=(18,15)) #
axes[0,0].set_title("Original", fontsize=15) 
axes[0,1].set_title("Prediction", fontsize=15)
axes[0,0].imshow(Y_test_sq[0])
axes[0,1].imshow(Y_test_predict_sq[0])
axes[1,0].imshow(Y_test_sq[1])
axes[1,1].imshow(Y_test_predict_sq[1])
plt.show()

"""# **Question 8**: Upload an image of cells either from one of your experiments or from the Internet (see Homework 1 on how to upload an image to Colab). Using the best model trained above, segment the images to identify the cells. Display the results for both image and predicted mask. How well did the model do? Remember you need to convert to grayscale and re-size and normalize the image (5 points total)"""

# Put your cells for Question 8 here
from google.colab import files
uploaded = files.upload()

from skimage.io import imread, imshow
from skimage.transform import resize
from skimage.color import rgb2gray


# (1) Open image with imread: img = imread(filename); the filename should be in quotes
# Make sure to include suffix (.tif, .png, .jpg) in the filename
# For example: img = imread('cell_image.png')
img = imread('cell.jpeg')
gray_img = rgb2gray(img)
imsave('cell.jpeg',gray_img)
imshow(gray_img)
img5= imread('W1_1.tif')
gray_img2 = rgb2gray(img5)
imsave('W1_1.tif', gray_img2)

cell_ids = ['cell.jpeg', 'W1_1.tif']
X_cell = makeImageDataTensor(cell_ids)

X_cell = np.expand_dims(X_cell, axis=-1)

model.load_weights('model-cell-1.h5')
Y_test_predictions = model.predict(X_cell)

print(X_cell.shape, Y_test_predictions.shape)
Y_test_sq = np.squeeze(X_cell)
Y_test_predict_sq = np.squeeze(Y_test_predictions)
X_test_sq = np.squeeze(X_test)
print(Y_test_sq.shape, Y_test_predict_sq.shape)

from skimage.io import imread, imshow
from skimage.transform import resize
from skimage.color import rgb2gray



fig, axes = plt.subplots(2,2, figsize=(18,15)) #
axes[0,0].set_title("Original", fontsize=15) 
axes[0,1].set_title("Prediction", fontsize=15)
axes[0,0].imshow(Y_test_sq[0])
axes[0,1].imshow(Y_test_predict_sq[0])
axes[1,0].imshow(Y_test_sq[1])
axes[1,1].imshow(Y_test_predict_sq[1])
plt.show()

"""This did not go very well... perhaps the resolution of the pictures may be to blame, also the cell expressing a tumorgeneic phenotype is also extremely unlike the cells that it was trained on so it makes sense that this was difficult to outline. I am surprised by how poorly the WT cell faired in this prediction.

# **Question 9:** Calculating Specificity, Precision, and Accuracy (5 pts)

See the Lecture 1 slide on the Confusion Matrix for more details.

## **Question 9A:** Write the functions for calculating the number of False Positives (FP) and False Negatives (FN). Use the functions for calculating True Positives (TP) and True Negatives (TN) as templates (2.5 pts)
"""

# Ans 9A: hw4 lecture 1 confusion matrix

# True positives
def calcTPs(pred_list, label_list):

    TP = 0
    # zip combines 2 lists so that they can be iterated at the same time
    for pred,label in zip(pred_list,label_list):
        if label == 1:
            if pred == label:
                TP = TP + 1 # TP += 1
    return TP

# True negatives
def calcTNs(pred_list, label_list):

    TN = 0
    for pred,label in zip(pred_list,label_list):
        if label == 0:
            if pred == label:
                TN = TN + 1 # TP += 1
    return TN

# False positives
def calcFPs(pred_list, label_list):

    FP = 0
    # zip combines 2 lists so that they can be iterated at the same time
    for pred,label in zip(pred_list,label_list):
        if label == 1:
            if pred == label:
                FP = FP + 1 # TP += 1
    return FP

# False negatives
def calcFNs(pred_list, label_list):

    FN = 0
    # zip combines 2 lists so that they can be iterated at the same time
    for pred,label in zip(pred_list,label_list):
        if label == 1:
            if pred == label:
                FN = FN + 1 # TP += 1
    return FN

"""## **Question 9B:** Write the functions for calculating Specificity, Precision, and Accuracy using the calcSensitivity and calcNPV functions as templates (2.5 pts)"""

#Ans 9B:

def calcSensitivity(TP,TN,FP,FN):
    return TP/(TP+FN)

def calcNPV(TP,TN,FP,FN):
    return TN/(TN+FN)

def calcSpecificity(TP,TN,FP,FN):
    return TN/(FP+TN)


def calcPrecision(TP,TN,FP,FN):
    return TP/(TP+FP)


def calcAccuracy(TP,TN,FP,FN):
    return (TP + TN)/(TP + FP + TN + FN)



"""#slide 11 from lecture 5-normalize image between 0-1, as predictions
#threshold function to convert into binary values
#if >= 1
#else 0
# **Question 10:** Calculate Specificity, Precision, and Accuracy at the pixel level betweeen your image and the prediction mask (5 pts)

There are several steps:

**A)** Convert image and mask from 2D array to 1D array to make computation easier

**B)** Convert the image and prediction mask into binary values using a threshold value so that they can be compared

**C)** Compare image and mask pixel-by-pixel to calculate TP, TN, FP, FN

**D)** Calculate sensitivity, precision, and accuracy

## **A)** Take image and prediction mask 2D arrays displayed in Question 8 and reshape them to 1D array. #.flatten()

Both the image and prediction mask should be normalized 512 x 512 2D arrays. If not, see above on how the image data is normalized and resized. If 3D array and not 2D, then use the np.squeeze() function.
"""

# Ans 10A:
X_Cell_1D =X_cell.flatten()
Y_Cell_1D =Y_test_predictions.flatten()

"""## **B)** Use the specified threshold_value (0.5) and the function apply_threshold() to convert 1D image and mask array values (0 to 1) into binary array values (0 or 1)."""

threshold_value = 0.5

# Inputs are a 1D array of values btw 0 and 1 along with a threshold value btw 0 and 1
def apply_threshold(input_array,thresh_value):
    # length of input_array
    lenArray = len(input_array)
    # output will be binary array of length lenArray
    binary_array = np.zeros(lenArray)
    for i in range(lenArray):
        # if input_array (pixel) value is greater than or equal to threshold, then set corresponding
        # binary pixel to be 1, otherwise 0
        if input_array[i] >= thresh_value:
            binary_array[i] = 1
        else:   
            binary_array[i] = 0

    return binary_array

#Ans 10B:
threshcellsx = apply_threshold(X_Cell_1D, threshold_value)
threshcellsy = apply_threshold(Y_Cell_1D, threshold_value)

"""#iterate one at a time true positive = 1 true negative = 0
## **C)** Do pixel-by-pixel comparison of image to mask to calculate TP, TN, FP, FN using your calcTPs(), calcTNs(), calcFPs(), calcFNs() functions in Question 9.

In other words, if the first pixel (index = 0) of the image is 1 and the first pixel of the prediction mask is 1, then that is a true positive (TP). If the image pixel is 1 and the prediction pixel is 0, then that is a false negative, etc. Sum up the number of TP, TN, FP, FN among all the pixels.
"""

# Ans 10C:
Truepos =calcTPs(threshcellsx,threshcellsy)
Trueneg =calcTNs(threshcellsx, threshcellsy)
Falsepos=calcFPs(threshcellsx, threshcellsy)
Falseneg=calcFNs(threshcellsx, threshcellsy)
print("True Positive: ", Truepos)
print("True Negative: ", Trueneg)  
print("False Positive: ",Falsepos)   
print("False Negative: ", Falseneg)

"""## **D)** Compute the sensitivity, precision, and accuracy of the binary prediction mask using the functions (e.g. calcSensitivity()) from Question 9"""

# Ans 10D:
sens=calcSensitivity(Truepos,Trueneg,Falsepos,Falseneg)
prec=calcPrecision(Truepos,Trueneg,Falsepos,Falseneg)
acc=calcAccuracy(Truepos,Trueneg,Falsepos,Falseneg)
print("Sensitivity: ", sens)
print("Precision: ", prec)
print("Accuracy: ", acc)

"""## **E)** Repeat the above (A to D) for a threshold value of 0.1"""

# Ans 10E:
threshold_value = 0.1

# Inputs are a 1D array of values btw 0 and 1 along with a threshold value btw 0 and 1
def apply_threshold(input_array,thresh_value):
    # length of input_array
    lenArray = len(input_array)
    # output will be binary array of length lenArray
    binary_array = np.zeros(lenArray)
    for i in range(lenArray):
        # if input_array (pixel) value is greater than or equal to threshold, then set corresponding
        # binary pixel to be 1, otherwise 0
        if input_array[i] >= thresh_value:
            binary_array[i] = 1
        else:   
            binary_array[i] = 0

    return binary_array
threshcellsx = apply_threshold(X_Cell_1D, threshold_value)
threshcellsy = apply_threshold(Y_Cell_1D, threshold_value)

Truepos =calcTPs(threshcellsx,threshcellsy)
Trueneg =calcTNs(threshcellsx, threshcellsy)
Falsepos=calcFPs(threshcellsx, threshcellsy)
Falseneg=calcFNs(threshcellsx, threshcellsy)
print("True Positive: ", Truepos)
print("True Negative: ", Trueneg)  
print("False Positive: ",Falsepos)   
print("False Negative: ", Falseneg)

sens=calcSensitivity(Truepos,Trueneg,Falsepos,Falseneg)
prec=calcPrecision(Truepos,Trueneg,Falsepos,Falseneg)
acc=calcAccuracy(Truepos,Trueneg,Falsepos,Falseneg)
print("Sensitivity: ", sens)
print("Precision: ", prec)
print("Accuracy: ", acc)

"""## **F)** Compare the sensitivity, precision and accuracy for the two threshold values (0.5 or 0.1). Which threshold gives the better binary prediction? Explain.

**Ans 10F:**
Sensitivity and precision remain the same between the treshold values of 0.5 and 0.1 The accuracy, however, decreases from ~0.423 with a treshold value of 0.5 to ~0.335 with a treshold value of 0.1. Thus, surprsingly, a treshold value of 0.5 apears to be a better binary predictor due to the fact that the precision and sensitivity remain unchanged, and generates a higher level of accuracy. We would expect higher sensitivity and accuracy using the treshold value of 0.1, however because the original prediction was not even close, changing the treshold does not have the desired outcome.
"""
